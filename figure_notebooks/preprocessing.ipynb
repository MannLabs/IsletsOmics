{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"src.py\")\n",
    "from src import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load proteomics data and reshape to data matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: sample_data : (18, 7285), sample_metadata : (18, 1), feature_metadata : (7285, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data_Proteome/proteomics_filtered.txt\"\n",
    "df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "\n",
    "# index\n",
    "sample_data = df.copy()\n",
    "sample_data.set_index(\"ProteinGroups\", inplace = True, drop = False)\n",
    "\n",
    "# sample data\n",
    "sample_data = sample_data.drop(['ProteinGroups', 'Genes', 'ProteinDescriptions'], axis = 1).T\n",
    "sample_data.index = sample_data.index.str.replace('ifng', 'ifng_').str.replace('control', 'control_')\n",
    "\n",
    "# feature metadata\n",
    "feature_metadata = df[['ProteinGroups', 'Genes', 'ProteinDescriptions']].copy()\n",
    "feature_metadata.set_index(\"ProteinGroups\", inplace = True, drop = False)\n",
    "\n",
    "# sample metadata\n",
    "sample_metadata = pd.DataFrame({\"sample\" : sample_data.index})\n",
    "sample_metadata.set_index(\"sample\", inplace = True, drop = False)\n",
    "\n",
    "print(f\"Data shapes: sample_data : {sample_data.shape}, sample_metadata : {sample_metadata.shape}, feature_metadata : {feature_metadata.shape}\")\n",
    "\n",
    "# Ensure alignment of data and metadata\n",
    "sample_metadata = sample_metadata.loc[sample_data.index]\n",
    "feature_metadata = feature_metadata.loc[sample_data.columns]\n",
    "\n",
    "# Save dataframes\n",
    "sample_data.to_pickle(os.path.join(data_dir, \"islets_proteomics_data.pkl\"))\n",
    "sample_metadata.to_pickle(os.path.join(data_dir, \"islets_proteomics_sample_metadata.pkl\"))\n",
    "feature_metadata.to_pickle(os.path.join(data_dir, \"islets_proteomics_feature_metadata.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "# Delete check\n",
    "\n",
    "sample_data_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_proteomics_data.pkl\")\n",
    "sample_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_proteomics_sample_metadata.pkl\")\n",
    "feature_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_proteomics_feature_metadata.pkl\")\n",
    "\n",
    "print(sample_data_old.equals(sample_data),\n",
    "sample_metadata_old.equals(sample_metadata),\n",
    "feature_metadata_old.equals(feature_metadata),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transcriptomics data and reshape to data matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptomics data shape: (17230, 35)\n",
      "Shape before deduplication: (13098, 21), shape after deduplication: (12993, 21), aggregated 105 rows.\n",
      "Data shapes: sample_data : (18, 12993), sample_metadata : (18, 1), feature_metadata : (12993, 3)\n"
     ]
    }
   ],
   "source": [
    "# data_path = \"./data_RNAseq/MARINE_ilots_ifng_expression_DeSeq2.xlsx\" # old dataset\n",
    "data_path = \"./data_RNAseq/ilots_ifng_expression_DeSeq2_Marine_20220610.xlsx\"\n",
    "df = pd.read_excel(data_path, engine = 'openpyxl')\n",
    "print(f\"Transcriptomics data shape: {df.shape}\")\n",
    "\n",
    "# remove unused columns\n",
    "mean_ratio_columns = [\n",
    "    'alpha.ctrl',\n",
    "    'alpha.IFNg',\n",
    "    'alpha.log2fc',\n",
    "    'alpha.p.value', \n",
    "    'alpha.p.adj',\n",
    "    'beta.ctrl',\n",
    "    'beta.IFNg',\n",
    "    'beta.log2fc',\n",
    "    'beta.p.value', \n",
    "    'beta.p.adj',\n",
    "    'delta.ctrl',\n",
    "    'delta.IFNg',\n",
    "    'delta.log2fc', \n",
    "    'delta.p.value', \n",
    "    'delta.p.adj'\n",
    "    ]\n",
    "df.drop(mean_ratio_columns, axis = 1, inplace = True)\n",
    "\n",
    "# Handle mapping of ENSEMBL to uniprot IDs using bioMart. Prefer static version of mapping dict due to possible API changes\n",
    "mapping_dict_name = \"2025-04-23_12_01_01_mmus_ref_dict.pkl\"\n",
    "if not os.path.exists(\"2025-04-23_12_01_01_mmus_ref_dict.pkl\"):\n",
    "    mapping_dict_name = f\"./{pd.Timestamp.now().strftime('%Y-%m-%d_%H_%M_%S')}_mmus_ref_dict.pkl\"\n",
    "    mmus_ref_dict = Utils.map_ensembl_to_uniprot('mmusculus', True)\n",
    "    pd.DataFrame.from_dict(mmus_ref_dict, orient = 'index', columns = ['uniprot_id']).to_pickle(mapping_dict_name)\n",
    "\n",
    "# load mmus_ref_dict from pickle file\n",
    "mmus_ref_dict = pd.read_pickle(mapping_dict_name)['uniprot_id'].to_dict()\n",
    "\n",
    "df['uniprot_id'] = df['ensembl.id'].map(mmus_ref_dict)\n",
    "df.set_index('uniprot_id', inplace = True, drop = False)\n",
    "\n",
    "# Remove rows with missing uniprot ids\n",
    "df.dropna(subset = ['uniprot_id'], inplace = True)\n",
    "\n",
    "# deduplicate by aggregation: average or sum per uniprot id.\n",
    "df = Utils.deduplicate_alphanumeric_dataframe(df, 'sum')\n",
    "\n",
    "# index\n",
    "sample_data = df.copy()\n",
    "sample_data.set_index('uniprot_id', inplace = True, drop = False)\n",
    "\n",
    "# sample data\n",
    "sample_data = sample_data.drop(['ensembl.id', 'gene.symbol', 'uniprot_id'], axis = 1).T\n",
    "sample_data.index = sample_data.index.str.lower()\n",
    "sample_data = Utils.nan_safe_df_log(sample_data, 2)\n",
    "\n",
    "# sample metadata\n",
    "sample_metadata = pd.DataFrame({\"sample\" : sample_data.index})\n",
    "sample_metadata.set_index(\"sample\", inplace = True, drop = False)\n",
    "\n",
    "# feature metadata\n",
    "feature_metadata = df[['ensembl.id', 'gene.symbol', 'uniprot_id']].copy()\n",
    "feature_metadata.set_index('uniprot_id', inplace = True, drop = False)\n",
    "\n",
    "print(f\"Data shapes: sample_data : {sample_data.shape}, sample_metadata : {sample_metadata.shape}, feature_metadata : {feature_metadata.shape}\")\n",
    "\n",
    "# Ensure alignment of data and metadata\n",
    "sample_metadata = sample_metadata.loc[sample_data.index]\n",
    "feature_metadata = feature_metadata.loc[sample_data.columns]\n",
    "\n",
    "# Save dataframes\n",
    "sample_data.to_pickle(os.path.join(data_dir, \"islets_transcriptomics_data.pkl\"))\n",
    "sample_metadata.to_pickle(os.path.join(data_dir, \"islets_transcriptomics_sample_metadata.pkl\"))\n",
    "feature_metadata.to_pickle(os.path.join(data_dir, \"islets_transcriptomics_feature_metadata.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "# Delete check\n",
    "\n",
    "sample_data_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_transcriptomics_data.pkl\")\n",
    "sample_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_transcriptomics_sample_metadata.pkl\")\n",
    "feature_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_transcriptomics_feature_metadata.pkl\")\n",
    "\n",
    "print(sample_data_old.equals(sample_data),\n",
    "sample_metadata_old.equals(sample_metadata),\n",
    "feature_metadata_old.equals(feature_metadata),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load phospho data and reshape to data matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: sample_data : (9, 7356), sample_metadata : (9, 7), feature_metadata : (7356, 25)\n"
     ]
    }
   ],
   "source": [
    "# load phospho data and reshape to data matrix\n",
    "data_path = \"./data_Phospho/celltype_psite.txt\"\n",
    "df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "\n",
    "# index\n",
    "sample_data = df.copy()\n",
    "sample_data.set_index('PTM_collapse_key', inplace = True, drop = False)\n",
    "\n",
    "# sample data\n",
    "sample_data = sample_data[[\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_07_alpha_01_S3-G1_1_2886',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_08_alpha_02_S3-H1_1_2887',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_09_alpha_03_S3-A2_1_2888',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_10_beta_01_S3-B2_1_2889',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_11_beta_02_S3-C2_1_2890',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_12_beta_03_S3-D2_1_2891',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_13_delta_01_S3-E2_1_2883',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_14_delta_02_S3-F2_1_2884',\n",
    "    '20230426_TIMS01scp_MCT_SA_whi20_AID12_DBS08_Phospho_15_delta_03_S3-G2_1_2885',]].T\n",
    "\n",
    "# Apply nan-safe log2 transformation\n",
    "sample_data = Utils.nan_safe_df_log(sample_data, 2)\n",
    "\n",
    "# sample_metadata\n",
    "sample_metadata = pd.DataFrame({\"sample\" : sample_data.index})\n",
    "sample_metadata.set_index(\"sample\", inplace = True, drop = False)\n",
    "sample_metadata['treat'] = 'control'\n",
    "sample_metadata['sample'] = sample_metadata.index.str.split('_').str[-5]\n",
    "sample_metadata['rep'] = sample_metadata.index.str.split('_').str[-4].astype(int).astype(str)\n",
    "sample_metadata['readout'] = 'phosphoproteomics'\n",
    "sample_metadata['sample_treat_readout'] = sample_metadata['sample'] + '_' + sample_metadata['treat'] + '_' + sample_metadata['readout']\n",
    "sample_metadata['sample_treat_rep_readout'] = sample_metadata['sample'] + '_' + sample_metadata['treat'] + '_' + sample_metadata['rep'] + '_' + sample_metadata['readout']\n",
    "\n",
    "# replace data index with matched metadata sample_treat_rep_readout\n",
    "sample_data = sample_data.join(sample_metadata['sample_treat_rep_readout'])\n",
    "sample_data.set_index('sample_treat_rep_readout', inplace = True, drop = True)\n",
    "\n",
    "# replace sample metadata index with sample_treat_rep_readout\n",
    "sample_metadata['PTM_collapse_key'] = sample_metadata.index\n",
    "sample_metadata.set_index('sample_treat_rep_readout', inplace = True, drop = False)\n",
    "\n",
    "# feature metadata\n",
    "feature_metadata = df[['R.Condition', 'PG.Genes', 'PG.Organisms', 'PG.ProteinDescriptions',\n",
    "       'PG.ProteinGroups', 'PG.ProteinNames', 'PG.UniProtIds',\n",
    "       'PEP.PeptidePosition', 'EG.IsDecoy', 'EG.PrecursorId',\n",
    "       'EG.PTMPositions..Phospho..STY..', 'EG.ApexRT',\n",
    "       'EG.PTMProbabilities..Phospho..STY..', 'EG.PTMSites..Phospho..STY..',\n",
    "       'EG.PTMAssayCandidateScore', 'EG.PTMAssayProbability',\n",
    "       'EG.PTMLocalizationProbabilities', 'EG.ProteinPTMLocations',\n",
    "       'EG.NormalizationFactor', 'PTM_0_num', 'PTM_group', 'PTM_collapse_key',\n",
    "       'PTM_collapse_key_num', 'PTM_localization', 'PTM_0_aa']].copy()\n",
    "feature_metadata.set_index('PTM_collapse_key', inplace = True, drop = False)\n",
    "\n",
    "print(f\"Data shapes: sample_data : {sample_data.shape}, sample_metadata : {sample_metadata.shape}, feature_metadata : {feature_metadata.shape}\")\n",
    "\n",
    "# Ensure alignment of data and metadata\n",
    "sample_metadata = sample_metadata.loc[sample_data.index]\n",
    "feature_metadata = feature_metadata.loc[sample_data.columns]\n",
    "feature_metadata.index.name = 'PTM_collapse_key'\n",
    "\n",
    "# Handle datatypes (legacy)\n",
    "feature_metadata['EG.IsDecoy'] = feature_metadata['EG.IsDecoy'].astype(object)\n",
    "feature_metadata['PTM_collapse_key_num'] = feature_metadata['PTM_collapse_key_num'].astype(object)\n",
    "feature_metadata['PTM_localization'] = feature_metadata['PTM_localization'].astype(object)\n",
    "\n",
    "# Save dataframes\n",
    "sample_data.to_pickle(os.path.join(data_dir, \"islets_phospho_data.pkl\"))\n",
    "sample_metadata.to_pickle(os.path.join(data_dir, \"islets_phospho_sample_metadata.pkl\"))\n",
    "feature_metadata.to_pickle(os.path.join(data_dir, \"islets_phospho_feature_metadata.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "# Delete check\n",
    "sample_data_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_phospho_data.pkl\")\n",
    "sample_data_old = Utils.nan_safe_df_log(sample_data_old, 2)\n",
    "sample_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_phospho_sample_metadata.pkl\")\n",
    "feature_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/data/datasets/islets_phospho_feature_metadata.pkl\")\n",
    "\n",
    "print(sample_data_old.equals(sample_data),\n",
    "sample_metadata_old.equals(sample_metadata),\n",
    "feature_metadata_old.equals(feature_metadata),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save usable datasets for proteomics and transcriptomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 5147)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/datasets\"\n",
    "subframes = ['alpha_control', 'beta_control', 'delta_control', 'alpha_ifng', 'beta_ifng', 'delta_ifng']\n",
    "\n",
    "# load proteomics data\n",
    "pdata = pd.read_pickle(os.path.join(data_dir, 'islets_proteomics_data.pkl'))\n",
    "\n",
    "# load transcriptomics data\n",
    "tdata = pd.read_pickle(os.path.join(data_dir, \"islets_transcriptomics_data.pkl\"))\n",
    "\n",
    "# annotate samples with respective modality\n",
    "pdata.index = [x + \"_proteomics\" for x in pdata.index]\n",
    "tdata.index = [x + \"_transcriptomics\" for x in tdata.index]\n",
    "\n",
    "id2pg = Utils.map_pg_to_id(pg_series = pdata.columns, id_series = tdata.columns)\n",
    "\n",
    "# transfer protein group IDs to transcriptomics data\n",
    "# tdata_mapped_colnames = tdata.columns.to_series().apply(lambda x: id2pg.get(x, x))\n",
    "# tdata.columns = tdata_mapped_colnames\n",
    "\n",
    "# transfer transcriptomics IDs to proteomics data\n",
    "pg2id = {v: k for k, v in id2pg.items()}\n",
    "pdata_mapped_colnames = pdata.columns.to_series().apply(lambda x: pg2id.get(x, x))\n",
    "pdata.columns = pdata_mapped_colnames\n",
    "\n",
    "# match proteomics and transcriptomics data by feature\n",
    "data = pdata.T.join(tdata.T, how = 'inner').T\n",
    "print(data.shape)\n",
    "\n",
    "# split idx\n",
    "sample_treat_rep_readout = data.index\n",
    "sample = sample_treat_rep_readout.str.split(\"_\").str[0]\n",
    "treat = sample_treat_rep_readout.str.split(\"_\").str[1]\n",
    "rep = sample_treat_rep_readout.str.split(\"_\").str[2]\n",
    "readout = sample_treat_rep_readout.str.split(\"_\").str[3]\n",
    "\n",
    "# make metadata\n",
    "sample_metadata = pd.DataFrame({\n",
    "    \"sample\": sample,\n",
    "    \"treat\" : treat,\n",
    "    \"rep\": rep,\n",
    "    \"readout\": readout,\n",
    "    \"sample_treat_readout\": [\"_\".join(x) for x in zip(sample, treat, readout)],\n",
    "}, index = data.index)\n",
    "\n",
    "# make feature metadata\n",
    "feature_metadata = data.columns.to_frame()\n",
    "if 'ProteinGroups' in feature_metadata.columns:\n",
    "    feature_metadata.drop(columns = ['ProteinGroups'], inplace = True)\n",
    "else:\n",
    "    feature_metadata.drop(columns = 0, inplace = True)\n",
    "\n",
    "# Ensure alignment of data and metadata\n",
    "sample_metadata = sample_metadata.loc[data.index]\n",
    "feature_metadata = feature_metadata.loc[data.columns]\n",
    "\n",
    "# Save dataframes\n",
    "data.to_pickle(os.path.join(data_dir, \"islets_rna_prot_dataset.pkl\"))\n",
    "sample_metadata.to_pickle(os.path.join(data_dir, \"islets_rna_prot_sample_metadata.pkl\"))\n",
    "feature_metadata.to_pickle(os.path.join(data_dir, \"islets_rna_prot_feature_metadata.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True False\n"
     ]
    }
   ],
   "source": [
    "# Delete check\n",
    "\n",
    "sample_data_old = pd.read_pickle(\"../../MaTh_Jun24/rna_prot_dataset.pkl\")\n",
    "sample_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/rna_prot_sample_metadata.pkl\")\n",
    "feature_metadata_old = pd.read_pickle(\"../../MaTh_Jun24/rna_prot_feature_metadata.pkl\")\n",
    "\n",
    "print(sample_data_old.equals(data),\n",
    "sample_metadata_old.equals(sample_metadata),\n",
    "feature_metadata_old.equals(feature_metadata),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save usable datasets for proteomics and transcriptomics and phosphoproteomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read phospho data\n",
    "data_dir = \"./data/datasets\"\n",
    "\n",
    "# load phosphoproteomics data\n",
    "ph_data = pd.read_pickle(os.path.join(data_dir, 'islets_phospho_data.pkl'))\n",
    "ph_sample_metadata = pd.read_pickle(os.path.join(data_dir, 'islets_phospho_sample_metadata.pkl'))\n",
    "ph_feature_metadata = pd.read_pickle(os.path.join(data_dir, 'islets_phospho_feature_metadata.pkl'))\n",
    "\n",
    "# load proteomics/transcriptomics data\n",
    "pt_data = pd.read_pickle(os.path.join(data_dir, 'islets_rna_prot_dataset.pkl'))\n",
    "pt_sample_metadata = pd.read_pickle(os.path.join(data_dir, 'islets_rna_prot_sample_metadata.pkl'))\n",
    "pt_feature_metadata = pd.read_pickle(os.path.join(data_dir, 'islets_rna_prot_feature_metadata.pkl'))\n",
    "\n",
    "# In order to join the data, we must reconcile the phospho-site features and the UniProt proteins:\n",
    "# Each UniProt ID can have multiple phospho-sites, so the final dataset features are the phospho-sites\n",
    "ph_data_uniprot_annotated = ph_data.T.join(ph_feature_metadata['PG.UniProtIds'], how = 'inner')\n",
    "\n",
    "# Join the proteomics/transcriptomics data by UniProt ID\n",
    "ptp_data = ph_data_uniprot_annotated.merge(pt_data.T, left_on = 'PG.UniProtIds', right_index = True, how = 'inner')\n",
    "\n",
    "# Extract feature metadata and drop the UniProt ID\n",
    "ptp_feature_metadata = ptp_data['PG.UniProtIds'].to_frame()\n",
    "ptp_data.drop(columns = ['PG.UniProtIds'], inplace = True)\n",
    "\n",
    "# Add the original phospho site feature metadata back in\n",
    "ptp_feature_metadata = ptp_feature_metadata.join(ph_feature_metadata.drop(columns = {'PG.UniProtIds'}), how = 'left')\n",
    "ptp_feature_metadata.index.name = ph_feature_metadata.index.name\n",
    "\n",
    "# Derive sample metadata from column names of ptp_data\n",
    "ptp_sample_metadata = ptp_data.columns.to_frame()\n",
    "ptp_sample_metadata.columns = ['sample_treat_rep_readout']\n",
    "\n",
    "# Add original sample metadata back in \n",
    "ptp_sample_metadata_unordered = pd.concat([pt_sample_metadata, ph_sample_metadata.drop(columns = {'sample_treat_rep_readout', 'PTM_collapse_key'})], axis = 0)\n",
    "ptp_sample_metadata = ptp_sample_metadata_unordered.loc[ptp_sample_metadata.index]\n",
    "\n",
    "# Ensure alignment of data and metadata\n",
    "ptp_data = ptp_data.T\n",
    "ptp_sample_metadata = ptp_sample_metadata.loc[ptp_data.index]\n",
    "ptp_feature_metadata = ptp_feature_metadata.loc[ptp_data.columns]\n",
    "\n",
    "# Save dataframes\n",
    "ptp_data.to_pickle(os.path.join(data_dir, \"islets_PTP_dataset.pkl\"))\n",
    "ptp_sample_metadata.to_pickle(os.path.join(data_dir, \"islets_PTP_sample_metadata.pkl\"))\n",
    "ptp_feature_metadata.to_pickle(os.path.join(data_dir, \"islets_PTP_feature_metadata.pkl\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
